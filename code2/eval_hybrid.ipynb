{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Vietnamese embedding model: keepitreal/vietnamese-sbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\rag\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "from model_config import VietnameseEmbeddings\n",
    "from elasticsearch import Elasticsearch\n",
    "# Kết nối tới Elasticsearch\n",
    "es = Elasticsearch(\n",
    "    \"https://my-elasticsearch-project-fc9fd1.es.ap-southeast-1.aws.elastic.cloud:443\",\n",
    "    api_key=\"aXY4NkpKUUJaNVNfUEdnZHdVZ186MExmVk1iclZRWWlrS1hpeDRhOWRGUQ==\"\n",
    ")\n",
    "index = \"base\"\n",
    "embeddings = VietnameseEmbeddings()\n",
    "excel = r\"D:\\DATN\\QA_System\\eval\\testset\\final_dataset_qa.xlsx\"\n",
    "chunks = pd.read_excel(excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu đánh giá...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  Theo số liệu tháng 01/2021, T...: 100%|██████████| 2560/2560 [10:51<00:00,  3.93it/s, Hit@20=0.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kết quả đánh giá:\n",
      "Hit@1: 0.5016\n",
      "MRR@1: 0.5016\n",
      "Hit@5: 0.8137\n",
      "MRR@5: 0.6278\n",
      "Hit@10: 0.8934\n",
      "MRR@10: 0.6385\n",
      "Hit@20: 0.9535\n",
      "MRR@20: 0.6427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "def search(query, top_k=1, k_vector=50):\n",
    "    # Mã hóa truy vấn thành vector\n",
    "    embedding = embeddings.embed_query(query)\n",
    "    time.sleep(0.05)\n",
    "    # Thực hiện hybrid search với RRF (Reciprocal Rank Fusion)\n",
    "    result = es.search(\n",
    "        index=index,\n",
    "        retriever = {\n",
    "                \"rrf\": {\n",
    "                    \"retrievers\": [\n",
    "                        {\n",
    "                            \"standard\": {\n",
    "                                \"query\": {\n",
    "                                    \"match\": {\n",
    "                                        \"text\": query\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"knn\": {\n",
    "                                \"field\": \"vector\",\n",
    "                                \"query_vector\": embedding,\n",
    "                                \"k\": k_vector,\n",
    "                                \"num_candidates\": k_vector * 2\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"rank_window_size\": k_vector,\n",
    "                    \"rank_constant\": 80\n",
    "                }\n",
    "            },     size = top_k\n",
    "\n",
    "    )\n",
    "    \n",
    "    # Trích xuất kết quả\n",
    "    res = [hit['_source'][\"metadata\"][\"source\"] for hit in result['hits']['hits']]\n",
    "    \n",
    "    return res\n",
    "\n",
    "def evaluate(excel_path, top_k_values=[1, 5, 10, 20]):\n",
    "    chunk = pd.read_excel(excel_path)\n",
    "    total_questions = len(chunk)\n",
    "    \n",
    "    # Khởi tạo bộ đếm điểm\n",
    "    hits = {k: 0 for k in top_k_values}\n",
    "    mrr = {k: 0 for k in top_k_values}\n",
    "    \n",
    "    # Add progress bar\n",
    "    progress_bar = tqdm(chunk.iterrows(), total=total_questions, desc=\"Evaluating questions\")\n",
    "    \n",
    "    for _, row in progress_bar:\n",
    "        question = row['question']\n",
    "        metadata = row['metadata']\n",
    "        if isinstance(metadata, str):\n",
    "            metadata = metadata.replace(\"'\", \"\\\"\")\n",
    "            try:\n",
    "                metadata = json.loads(metadata)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        correct_source = metadata\n",
    "        \n",
    "\n",
    "        # Update progress bar description with current question\n",
    "        progress_bar.set_description(f\"Processing: {question[:30]}...\")\n",
    "        \n",
    "        # Thực hiện tìm kiếm\n",
    "        search_results = search(question, top_k=max(top_k_values))\n",
    "\n",
    "        # Kiểm tra kết quả và tính điểm\n",
    "        sources = [result for result in search_results]\n",
    "        # print(\"correct source:\",correct_source)\n",
    "        # print(\"search_results:\",search_results)\n",
    "        # print(\"sources:\",sources)\n",
    "        for k in top_k_values:\n",
    "            if correct_source in sources[:k]:\n",
    "                hits[k] += 1\n",
    "                rank = sources.index(correct_source) + 1\n",
    "                mrr[k] += 1 / rank if rank <= k else 0\n",
    "        \n",
    "        # Update progress bar postfix with current stats\n",
    "        progress_bar.set_postfix({f'Hit@{max(top_k_values)}': f'{(hits[max(top_k_values)] / (progress_bar.n + 1)):.2f}'})\n",
    "    \n",
    "    # Close progress bar\n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Tính tỷ lệ điểm\n",
    "    hit_ratios = {k: hits[k] / total_questions for k in top_k_values}\n",
    "    mrr_scores = {k: mrr[k] / total_questions for k in top_k_values}\n",
    "    \n",
    "    # Ghi kết quả vào Excel với timestamp\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = f\"evaluation_results_{timestamp}.xlsx\"\n",
    "    result_df = pd.DataFrame({\n",
    "        'Hit@k': [f\"Hit@{k}\" for k in top_k_values],\n",
    "        'Hit Ratio': [hit_ratios[k] for k in top_k_values],\n",
    "        'MRR': [mrr_scores[k] for k in top_k_values]\n",
    "    })\n",
    "    \n",
    "    result_df.to_excel(output_file, index=False)\n",
    "    return hit_ratios, mrr_scores\n",
    "\n",
    "# Chạy đánh giá\n",
    "excel_path = excel  # Đường dẫn tới file Excel\n",
    "print(\"Bắt đầu đánh giá...\")\n",
    "hit_ratios, mrr_scores = evaluate(excel_path)\n",
    "\n",
    "# In kết quả\n",
    "print(\"\\nKết quả đánh giá:\")\n",
    "for k in sorted(hit_ratios.keys()):\n",
    "    print(f\"Hit@{k}: {hit_ratios[k]:.4f}\")\n",
    "    print(f\"MRR@{k}: {mrr_scores[k]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả tổng hợp đã được lưu vào total_results_summary_1_5_10_20.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Thư mục chứa các file Excel\n",
    "folder_path = r\"D:\\DATN\\chatbot\\code\"\n",
    "\n",
    "# Lấy danh sách các file Excel trong thư mục\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# Danh sách để chứa kết quả từ các file\n",
    "all_results = []\n",
    "\n",
    "# Đọc mỗi file Excel và tổng hợp kết quả\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Lấy các giá trị Hit@k và MRR từ file Excel\n",
    "    hit_ratios = df[df['Hit@k'].str.startswith('Hit@')]['Hit Ratio'].values\n",
    "    mrr_scores = df[df['Hit@k'].str.startswith('Hit@')]['MRR'].values\n",
    "    \n",
    "    # Gắn kịch bản (tên file) vào dữ liệu\n",
    "    result = {\n",
    "        'Scenario': file,\n",
    "        'Hit@1': hit_ratios[0] if len(hit_ratios) > 0 else None,\n",
    "        'MRR@1': mrr_scores[0] if len(mrr_scores) > 0 else None,\n",
    "        'Hit@5': hit_ratios[1] if len(hit_ratios) > 1 else None,\n",
    "        'MRR@5': mrr_scores[1] if len(mrr_scores) > 1 else None,\n",
    "        'Hit@10': hit_ratios[2] if len(hit_ratios) > 2 else None,\n",
    "        'MRR@10': mrr_scores[2] if len(mrr_scores) > 2 else None,\n",
    "        'Hit@20': hit_ratios[3] if len(hit_ratios) > 3 else None,\n",
    "        'MRR@20': mrr_scores[3] if len(mrr_scores) > 3 else None,\n",
    "    }\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "# Chuyển đổi danh sách kết quả thành DataFrame\n",
    "combined_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Sắp xếp lại cột theo thứ tự để Hit và MRR xen kẽ\n",
    "combined_df = combined_df[['Scenario', 'Hit@1', 'MRR@1', 'Hit@5', 'MRR@5', 'Hit@10', 'MRR@10', 'Hit@20', 'MRR@20']]\n",
    "\n",
    "# Lưu kết quả tổng hợp vào một file Excel mới\n",
    "combined_df.to_excel(r\"D:\\DATN\\chatbot\\code\\total_results_summary_1_5_10_20.xlsx\", index=False)\n",
    "\n",
    "# In ra kết quả tổng hợp\n",
    "print(\"Kết quả tổng hợp đã được lưu vào total_results_summary_1_5_10_20.xlsx.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'Quy định Học bổng KKHT 2023.txt', 'id': '0'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(query, top_k=1, k_vector=50):\n",
    "    # Mã hóa truy vấn thành vector\n",
    "    embedding = embeddings.embed_query(query)\n",
    "    \n",
    "    # Thực hiện hybrid search với RRF (Reciprocal Rank Fusion)\n",
    "    result = es.search(\n",
    "        index=index,\n",
    "        retriever = {\n",
    "                \"rrf\": {\n",
    "                    \"retrievers\": [\n",
    "                        {\n",
    "                            \"standard\": {\n",
    "                                \"query\": {\n",
    "                                    \"match\": {\n",
    "                                        \"text\": query\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"knn\": {\n",
    "                                \"field\": \"vector\",\n",
    "                                \"query_vector\": embedding,\n",
    "                                \"k\": k_vector,\n",
    "                                \"num_candidates\": k_vector * 2\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"rank_window_size\": k_vector,\n",
    "                    \"rank_constant\": 60\n",
    "                }\n",
    "            },     size = top_k\n",
    "\n",
    "    )\n",
    "    \n",
    "    # Trích xuất kết quả\n",
    "    res = [hit['_source'][\"metadata\"][\"source\"] for hit in result['hits']['hits']]\n",
    "    \n",
    "    return res\n",
    "search(\"Đại học bách khoa hà nội\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
