{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\DATN\\QA_System\\eval\n",
      "['.env', '.env.example', '.git', '.gitignore', 'code', 'data_analyze', 'data_hust', 'docker-compose.yml', 'docker_help.md', 'eval', 'img', 'README.md', 'requirements.txt', 'volumes']\n",
      "['app.log', 'app.py', 'check_db.py', 'chunking.py', 'clutering.py', 'data_ingestion.py', 'final_df768.pkl', 'milvus_db.py', 'model_config.py', 'pipeline.ipynb', 'pipeline.py', 'raptor.ipynb', 'raptor.py', 'raptorpipeline.py', 'test.ipynb', 'utils.py', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # In thư mục hiện tại\n",
    "print(os.listdir(r\"D:\\DATN\\QA_System\"))  # Kiểm tra nội dung thư mục QA_System\n",
    "print(os.listdir(r\"D:\\DATN\\QA_System\\code\"))  # Kiểm tra nội dung thư mục code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "code_path = r\"D:\\DATN\\QA_System\\code\"\n",
    "sys.path.append(code_path)\n",
    "\n",
    "# Import trực tiếp từ các file\n",
    "from utils import convert_df_to_documents\n",
    "from model_config import VietnameseEmbeddings, load_gemini2\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "def load_final_df():\n",
    "    final_df_path = r\"D:\\DATN\\QA_System\\data_analyze\\finaldf.pkl\"\n",
    "    if os.path.exists(final_df_path):\n",
    "        final_df = pd.read_pickle(final_df_path)\n",
    "        print(f\"Đã load final_df từ file: {final_df_path}\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"File final_df chưa tồn tại.\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã load final_df từ file: D:\\DATN\\QA_System\\data_analyze\\finaldf.pkl\n",
      "Processed 1198 out of 1198 documents.\n"
     ]
    }
   ],
   "source": [
    "final_df = load_final_df()\n",
    "documents = convert_df_to_documents(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Vietnamese embedding model: keepitreal/vietnamese-sbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\rag\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding = VietnameseEmbeddings()\n",
    "model = load_gemini2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper \n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
    "#generator_llm = LangchainLLMWrapper(model)\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:   2%|▏         | 21/1198 [00:01<01:15, 15.68it/s]  Node 795558b6-c6b6-4fc0-b302-17edc4c536e3 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:   5%|▍         | 54/1198 [00:03<00:58, 19.49it/s]Node 1d267675-c42a-4e29-8a3d-c3024fd6d31a does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:   5%|▍         | 58/1198 [00:03<00:50, 22.76it/s]Node a437378f-598f-4da6-b0f1-0dd411a60467 does not have a summary. Skipping filtering.\n",
      "Node 99258e67-5344-4c28-b2fa-4b4bb986a02c does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:   5%|▌         | 61/1198 [00:03<00:56, 20.25it/s]Node b833f5bd-40bf-4f12-aff2-e39546a26baf does not have a summary. Skipping filtering.\n",
      "Node 3b7c7bba-c243-41cb-afe8-11eb216fa900 does not have a summary. Skipping filtering.\n",
      "Node 4fb7c4e9-c9a0-4e6a-ab17-97b2cb44c83b does not have a summary. Skipping filtering.\n",
      "Node 54059ad1-dd81-4c36-ba77-e463aac023a3 does not have a summary. Skipping filtering.\n",
      "Node faec07df-a769-40c5-b00b-31e9fbb1b7d4 does not have a summary. Skipping filtering.\n",
      "Node bb4df28c-f6cc-43bc-8931-181d220cab6f does not have a summary. Skipping filtering.\n",
      "Node 0f49873b-3cf1-47c2-84de-74f3974a4ec7 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  10%|█         | 123/1198 [00:06<00:54, 19.65it/s]Node 6335fc2a-5dca-40f4-b125-8710938f0aaf does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  17%|█▋        | 198/1198 [00:10<01:11, 14.04it/s]Node ebb7790f-db63-45eb-b7f6-a3ec22a3a149 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  17%|█▋        | 203/1198 [00:10<00:56, 17.61it/s]Node f90faf52-db89-4adf-b342-89251ede85ce does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  19%|█▉        | 233/1198 [00:12<00:54, 17.62it/s]Node 9f7ab032-3355-469f-a9f1-8b22f1566bf8 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  20%|██        | 245/1198 [00:13<00:48, 19.48it/s]Node c916e3fc-6bbe-491b-b68c-c2c585590bb0 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  27%|██▋       | 320/1198 [00:16<00:51, 17.05it/s]Node a55515bb-0ae5-4b47-90c8-d5b49fd62d53 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  40%|████      | 484/1198 [00:25<00:41, 17.09it/s]Node ab7aac28-4f2c-419f-b5a3-2e91d9c99312 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  58%|█████▊    | 691/1198 [00:36<00:27, 18.54it/s]Node 18b125bf-0373-4b9a-97c4-c9de21fbcc9e does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  72%|███████▏  | 866/1198 [00:46<00:20, 16.39it/s]Node d614fc2f-1f36-430f-837c-21086f239622 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  75%|███████▌  | 904/1198 [00:48<00:13, 21.23it/s]Node e43592e8-62e8-474a-a9e4-a10befe6df05 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  76%|███████▌  | 907/1198 [00:48<00:13, 21.53it/s]Node 06481c7f-51fd-4c02-8c7c-c73e815903a4 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  77%|███████▋  | 919/1198 [00:48<00:10, 25.40it/s]Node 35b94073-3970-4fcc-9b97-18a93f88136f does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  79%|███████▉  | 946/1198 [00:50<00:12, 20.33it/s]Node 39548c30-1572-44e9-95b6-335d22986c39 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  82%|████████▏ | 978/1198 [00:51<00:09, 23.90it/s]Node c1351364-7bd9-4b33-b4de-53679564e96c does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  86%|████████▌ | 1025/1198 [00:54<00:11, 14.60it/s]Node 8db0c630-61d2-45d4-9817-b233720b3110 does not have a summary. Skipping filtering.\n",
      "Node 2ace5a56-e299-43a9-88f7-50d78610f938 does not have a summary. Skipping filtering.\n",
      "Node 28b88a0d-7735-4f5a-a02e-de68e687065e does not have a summary. Skipping filtering.\n",
      "Node 80668bbd-f0d6-4eda-9dec-7648957136b4 does not have a summary. Skipping filtering.\n",
      "Node 4ccbcd1d-6582-4cdf-b282-30a4c32cd8c4 does not have a summary. Skipping filtering.\n",
      "Node c4ad6b35-e69c-4143-93b7-b80b6dca0c07 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  87%|████████▋ | 1046/1198 [00:55<00:07, 19.86it/s]Node 4db925b9-118e-4fe8-8dcc-92b4cf2662bc does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  89%|████████▊ | 1062/1198 [00:56<00:07, 18.71it/s]Node a0b476f1-8e02-49f8-b43d-45c3052f2924 does not have a summary. Skipping filtering.\n",
      "Node 9cfe18b0-b086-4952-a0b3-11a4d56c13ba does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  89%|████████▉ | 1065/1198 [00:56<00:06, 19.58it/s]Node 63c2fd60-6dd3-430b-a58f-122df2d67909 does not have a summary. Skipping filtering.\n",
      "Node d553867e-c5c4-42a7-857c-da796ffbb311 does not have a summary. Skipping filtering.\n",
      "Node 6bc795ab-791d-44f3-84d1-31398c2773d3 does not have a summary. Skipping filtering.\n",
      "Node 9dab5f3d-f964-41a3-8bf3-c2b23225de13 does not have a summary. Skipping filtering.\n",
      "Node 10dfbcaa-c400-4b0c-b0d9-9d87e7944af3 does not have a summary. Skipping filtering.\n",
      "Node 5bf1bf8a-1783-40b9-9760-b6d8fe02d42f does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  90%|████████▉ | 1074/1198 [00:56<00:03, 31.77it/s]Node 4f5cb12a-2635-4246-ad7f-198c0b439eb7 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  90%|█████████ | 1083/1198 [00:56<00:04, 26.79it/s]Node 189b78be-b6f8-43ac-bcc7-24c86d8831e5 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  91%|█████████ | 1091/1198 [00:57<00:04, 25.08it/s]Node bd0793fc-20b2-4616-bfaf-842c3d0b46c9 does not have a summary. Skipping filtering.\n",
      "Node 2643876d-da8b-4c07-98b8-77908339be45 does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  94%|█████████▎| 1123/1198 [00:58<00:04, 16.90it/s]Node 0a67fe5c-fea0-4525-8102-d4fceef919ea does not have a summary. Skipping filtering.\n",
      "Applying CustomNodeFilter:  96%|█████████▌| 1149/1198 [01:00<00:02, 18.41it/s]Node bed2ad6e-dd47-4931-99d7-8cfd3f10fe62 does not have a summary. Skipping filtering.\n",
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]                                                 \n",
      "Generating Scenarios: 100%|██████████| 2/2 [00:12<00:00,  6.12s/it]\n",
      "Generating Samples: 100%|██████████| 10/10 [00:06<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(documents, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is PGS.TS. Huỳnh Đăng Chính?</td>\n",
       "      <td>[Giám đốc Đại học: PGS.TS. Huỳnh Quyết Thắng\\n...</td>\n",
       "      <td>PGS.TS. Huỳnh Đăng Chính is a Vice Director at...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you provide detailed contact information...</td>\n",
       "      <td>[Cụm văn bản này cung cấp thông tin liên hệ củ...</td>\n",
       "      <td>The context provides the name and title of PGS...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the development goals of Đại học Bách...</td>\n",
       "      <td>[CHIẾN LƯỢC PHÁT TRIỂN\\nTÓM LƯỢC CHIẾN LƯỢC PH...</td>\n",
       "      <td>The development goals of Đại học Bách Khoa Hà ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cach mang cong nghiep 4.0 la gi?</td>\n",
       "      <td>[Tóm tắt Chiến lược Phát triển Đại học Bách Kh...</td>\n",
       "      <td>Chiến lược phát triển của Đại học Bách Khoa Hà...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what happen in 2020 at hanoi university?</td>\n",
       "      <td>[CHƯƠNG TRÌNH ĐÀO TẠO KỸ SƯ CHUYÊN SÂU ĐẶC THÙ...</td>\n",
       "      <td>In 2020, Hanoi University of Science and Techn...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Where can students find detailed instructions ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nMật khẩu email: Liên hệ Trung tâm ...</td>\n",
       "      <td>Students can find detailed instructions for us...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What role does the 'Hội đồng xét' play in the ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2. Phòng/Ban chức năng Đào tạo: Cu...</td>\n",
       "      <td>The 'Hội đồng xét' plays a crucial role in bot...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who are TS. Nguyễn An Hưng and TS. Nguyễn Hồng...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nCụm văn bản cung cấp thông tin về ...</td>\n",
       "      <td>TS. Nguyễn An Hưng is the Phó Bí thư Đoàn trườ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How Trường ĐH Bách khoa Hà Nội make sure their...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nTheo đó, Trường ĐH Bách khoa Hà Nộ...</td>\n",
       "      <td>Trường ĐH Bách khoa Hà Nội ensures their speci...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do the regulations outlined in Quyết định ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n3. Mức phí gửi xe: Mức phí gửi xe ...</td>\n",
       "      <td>The regulations outlined in Quyết định số 44/2...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0                   Who is PGS.TS. Huỳnh Đăng Chính?   \n",
       "1  Could you provide detailed contact information...   \n",
       "2  What are the development goals of Đại học Bách...   \n",
       "3                   Cach mang cong nghiep 4.0 la gi?   \n",
       "4           what happen in 2020 at hanoi university?   \n",
       "5  Where can students find detailed instructions ...   \n",
       "6  What role does the 'Hội đồng xét' play in the ...   \n",
       "7  Who are TS. Nguyễn An Hưng and TS. Nguyễn Hồng...   \n",
       "8  How Trường ĐH Bách khoa Hà Nội make sure their...   \n",
       "9  How do the regulations outlined in Quyết định ...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [Giám đốc Đại học: PGS.TS. Huỳnh Quyết Thắng\\n...   \n",
       "1  [Cụm văn bản này cung cấp thông tin liên hệ củ...   \n",
       "2  [CHIẾN LƯỢC PHÁT TRIỂN\\nTÓM LƯỢC CHIẾN LƯỢC PH...   \n",
       "3  [Tóm tắt Chiến lược Phát triển Đại học Bách Kh...   \n",
       "4  [CHƯƠNG TRÌNH ĐÀO TẠO KỸ SƯ CHUYÊN SÂU ĐẶC THÙ...   \n",
       "5  [<1-hop>\\n\\nMật khẩu email: Liên hệ Trung tâm ...   \n",
       "6  [<1-hop>\\n\\n2. Phòng/Ban chức năng Đào tạo: Cu...   \n",
       "7  [<1-hop>\\n\\nCụm văn bản cung cấp thông tin về ...   \n",
       "8  [<1-hop>\\n\\nTheo đó, Trường ĐH Bách khoa Hà Nộ...   \n",
       "9  [<1-hop>\\n\\n3. Mức phí gửi xe: Mức phí gửi xe ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  PGS.TS. Huỳnh Đăng Chính is a Vice Director at...   \n",
       "1  The context provides the name and title of PGS...   \n",
       "2  The development goals of Đại học Bách Khoa Hà ...   \n",
       "3  Chiến lược phát triển của Đại học Bách Khoa Hà...   \n",
       "4  In 2020, Hanoi University of Science and Techn...   \n",
       "5  Students can find detailed instructions for us...   \n",
       "6  The 'Hội đồng xét' plays a crucial role in bot...   \n",
       "7  TS. Nguyễn An Hưng is the Phó Bí thư Đoàn trườ...   \n",
       "8  Trường ĐH Bách khoa Hà Nội ensures their speci...   \n",
       "9  The regulations outlined in Quyết định số 44/2...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  \n",
       "3  single_hop_specifc_query_synthesizer  \n",
       "4  single_hop_specifc_query_synthesizer  \n",
       "5  multi_hop_specific_query_synthesizer  \n",
       "6  multi_hop_specific_query_synthesizer  \n",
       "7  multi_hop_specific_query_synthesizer  \n",
       "8  multi_hop_specific_query_synthesizer  \n",
       "9  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import load_dataset\n",
    "\n",
    "# loading the V2 dataset\n",
    "# amnesty_qa = load_dataset(\"explodinggradients/amnesty_qa\", \"english_v2\")[\"eval\"]\n",
    "# amnesty_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS expects a file_name dict as key\n",
    "for document in chunks:\n",
    "    document.metadata['file_name'] = document.metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "model = ChatOpenAI()\n",
    "\n",
    "vectorstore = Chroma.from_documents(chunks, embedding)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\",\"question\"]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = testset.to_pandas()[\"question\"].to_list()\n",
    "ground_truth = testset.to_pandas()[\"ground_truth\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = testset.to_pandas()[\"question\"].to_list()\n",
    "ground_truth = testset.to_pandas()[\"ground_truth\"].to_list()\n",
    "\n",
    "data = {\"question\": [], \"answer\": [], \"contexts\": [], \"ground_truth\": ground_truth}\n",
    "\n",
    "for query in questions:\n",
    "    data[\"question\"].append(query)\n",
    "    data[\"answer\"].append(rag_chain.invoke(query))\n",
    "    data[\"contexts\"].append([doc.page_content for doc in retriever.get_relevant_documents(query)])\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset,\n",
    "    metrics=[\n",
    "        context_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "df = result.to_pandas()\n",
    "\n",
    "heatmap_data = df[['context_relevancy', 'context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']]\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('green_red', ['red', 'green'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", linewidths=.5, cmap=cmap)\n",
    "\n",
    "plt.yticks(ticks=range(len(df['question'])), labels=df['question'], rotation=0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add LangFuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(\n",
    "  secret_key=\"sk-lf-8be80c67-4187-4e43-9d01-544195dc9f03\",\n",
    "  public_key=\"pk-lf-d7653f64-8086-4365-b05c-865ead3478a3\",\n",
    "  host=\"http://localhost:3000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = langfuse.trace(\n",
    "    name = \"eval\",\n",
    "    user_id = \"eval_user\",\n",
    "    metadata = {\n",
    "        \"email\": \"prod@company.com\",\n",
    "    },\n",
    "    tags = [\"evaluation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    for metric_name in [\"faithfulness\", \"answer_relevancy\", \"context_recall\"]:\n",
    "        langfuse.score(\n",
    "            name=metric_name,\n",
    "            value=row[metric_name],\n",
    "            trace_id=trace.id\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
